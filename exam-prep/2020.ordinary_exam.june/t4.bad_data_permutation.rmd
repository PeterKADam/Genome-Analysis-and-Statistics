---
output:
  html_document:
        theme: readable
editor_options: 
  chunk_output_type: console
---

# A really bad experiment

Imagine that I have a machine that records static noise from the atmosphere and convert it to two values (x and y).

On two different nights I recorded the following data (night A and B)

```{r message=FALSE, warning=FALSE}

library(tidyverse)

df <- read_tsv(file = "t4.dataset.bad_data_permutation.tsv")

```

>Q4.1 How many datapoints did I collect in total?

>Q4.2 How many datapoints did I collect in group A?

>Q4.3 What is the mean x value in group A?

>Q4.4 What is the absolute difference in means of x in the two groups?

Hint: abs(-3.5) = 3.5


Make a scatterplot of x and y for the two groups separatedly.

>Q4.5 What number is hidden in group A?

>Q4.6 What number is hidden in group B?


After looking at the data we can see that the x values are NOT normally distrited.

Despite the peculiar results above we try and look for other patterns in the data.

We specifically try to test if mean(x) is different in night A versus night B.

If we try and do a simple t.test (assuming equal variance in the two groups) we get:

```{r}

groupA <- df %>% filter(group=="A")
groupB <- df %>% filter(group=="B")

t.test(x = groupA$x,y = groupB$x, var.equal = T)

```

>Q4.7 What is the p value we get from this bad test?


I really do not trust my test.

So I go ahead and make a permutation test using the following simple code (only 100 permutations)

```{r}

set.seed(0)
permuted   <- rep(NA, 100)
for (i in 1:length(permuted)) {
  xvalues <- sample(df$x)
  g1 <- mean(xvalues[df$group=="A"])
  g2 <- mean(xvalues[df$group=="B"])
  permuted[i] <- abs(g1 - g2)
}

permuted

```


>Q4.8 How many of the 100 permutations were equal to or more extreme than the observed difference?


>Q4.9 What is the estimated p value based on 5000 permutations?



